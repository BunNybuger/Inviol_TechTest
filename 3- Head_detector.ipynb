{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.transforms import functional as F\n",
    "from PIL import Image, ImageDraw, ImageFilter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\noor/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-7-21 Python-3.8.17 torch-2.0.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 396 layers, 35462484 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "Using cache found in C:\\Users\\noor/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-7-21 Python-3.8.17 torch-2.0.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5m summary: 290 layers, 20852934 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "# Load YOLOv5 models\n",
    "person_model_path = './1-models/Person_Detector.pt'\n",
    "head_model_path = './1-models/Head_detector_fromPersonBox_yolov5.pt'\n",
    "\n",
    "\n",
    "person_model = torch.hub.load('ultralytics/yolov5', 'custom', path=person_model_path)\n",
    "head_model = torch.hub.load('ultralytics/yolov5', 'custom', path=head_model_path)\n",
    "\n",
    "\n",
    "# Define a function to blur faces\n",
    "def blur_faces(image, head_boxes,blur=False):\n",
    "    blurred_image = image.copy()\n",
    "    for box in head_boxes:\n",
    "        x1, y1, x2, y2 = map(int, box)  # Convert to integer coordinates\n",
    "        face_region = image.crop((x1, y1, x2, y2))\n",
    "        if blur:\n",
    "            face_region = face_region.filter(ImageFilter.BLUR)\n",
    "            face_region = face_region.filter(ImageFilter.BLUR)\n",
    "            blurred_face = face_region.filter(ImageFilter.BLUR)\n",
    "\n",
    "        else:\n",
    "            blurred_face = Image.new('RGB', (x2 - x1, y2 - y1), (0, 0, 0))\n",
    "        blurred_image.paste(blurred_face, (x1, y1, x2, y2))\n",
    "    return blurred_image\n",
    "\n",
    "# to ignore other files in dataset and only care about images\n",
    "def is_image_file(filename):\n",
    "    img_extensions = ['.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tiff', '.webp']\n",
    "    return any(filename.lower().endswith(ext) for ext in img_extensions)\n",
    "\n",
    "# Process the dataset\n",
    "# input_folder = './2-dataset/COCO200'\n",
    "# output_folder = './4-output/blurred_COCO200'\n",
    "\n",
    "input_folder = './2-dataset/Sample2'\n",
    "output_folder = './4-output/blurred_Sample2'\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for root, _, files in os.walk(input_folder):\n",
    "    for filename in files:\n",
    "        if is_image_file(filename):\n",
    "            image_path = os.path.join(root, filename)\n",
    "            img = Image.open(image_path)\n",
    "            \n",
    "            # Step 1: Detect persons using the first model\n",
    "            results_person = person_model(img)\n",
    "            persons = results_person.pandas().xyxy[0]\n",
    "            person_boxes = persons[persons['name'] == 'person'][['xmin', 'ymin', 'xmax', 'ymax']].values.tolist()\n",
    "            \n",
    "            # Step 2: Detect heads using the second model\n",
    "            head_boxes = []\n",
    "            for box in person_boxes:\n",
    "                x1, y1, x2, y2 = box\n",
    "                person_region = img.crop((x1, y1, x2, y2))\n",
    "                results_head = head_model(person_region)\n",
    "                heads = results_head.pandas().xyxy[0]\n",
    "                if 'head' in heads['name'].values:\n",
    "                    head = heads[heads['name'] == 'head'][['xmin', 'ymin', 'xmax', 'ymax']].values[0]\n",
    "                    head_boxes.append([x1 + head[0], y1 + head[1], x1 + head[2], y1 + head[3]])\n",
    "            \n",
    "            # Step 3: Save YOLO format .txt file with head bounding boxes\n",
    "            rel_image_path = os.path.relpath(image_path, input_folder)\n",
    "            txt_output_path = os.path.join(output_folder, os.path.splitext(rel_image_path)[0] + '.txt')\n",
    "            os.makedirs(os.path.dirname(txt_output_path), exist_ok=True)\n",
    "            \n",
    "            with open(txt_output_path, 'w') as f:\n",
    "                for box in head_boxes:\n",
    "                    f.write(f\"head {box[0]} {box[1]} {box[2]} {box[3]}\\n\")\n",
    "            \n",
    "            # Step 4: Save the new dataset with blurred faces\n",
    "            rel_output_folder = os.path.relpath(output_folder, input_folder)\n",
    "            output_image_path = os.path.join(output_folder, rel_image_path)\n",
    "            os.makedirs(os.path.dirname(output_image_path), exist_ok=True)\n",
    "            \n",
    "            # If blur = False it will put a black box instead of head.\n",
    "            # set blur = True if you do not like the black box!\n",
    "            blurred_image = blur_faces(img, head_boxes, blur = False)\n",
    "            blurred_image.save(output_image_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "last_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
