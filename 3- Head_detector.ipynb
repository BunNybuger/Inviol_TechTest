{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = './2-dataset/COCO'   #Just the main folder (subfolders will be processed as well)\n",
    "output_path = './4-output/blurred_COCO' #will be created in code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\noor/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "WARNING  'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n",
      "WARNING  'ultralytics.yolo.utils' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.utils' instead.\n",
      "Note this warning may be related to loading older models. You can update your model to current structure with:\n",
      "    import torch\n",
      "    ckpt = torch.load(\"model.pt\")  # applies to both official and custom models\n",
      "    torch.save(ckpt, \"updated-model.pt\")\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['gitpython>=3.1.30'] not found, attempting AutoUpdate...\n",
      "Collecting gitpython>=3.1.30\n",
      "  Downloading GitPython-3.1.32-py3-none-any.whl (188 kB)\n",
      "     ------------------------------------ 188.5/188.5 kB 518.2 kB/s eta 0:00:00\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython>=3.1.30)\n",
      "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
      "     ---------------------------------------- 62.7/62.7 kB 1.1 MB/s eta 0:00:00\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython>=3.1.30)\n",
      "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: smmap, gitdb, gitpython\n",
      "Successfully installed gitdb-4.0.10 gitpython-3.1.32 smmap-5.0.0\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success  6.7s, installed 1 package: ['gitpython>=3.1.30']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "YOLOv5  2023-7-21 Python-3.8.17 torch-2.0.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 396 layers, 35462484 parameters, 0 gradients\n",
      "Adding AutoShape... \n",
      "Using cache found in C:\\Users\\noor/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-7-21 Python-3.8.17 torch-2.0.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5m summary: 290 layers, 20852934 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# from torchvision.transforms import functional as F\n",
    "# from PIL import Image, ImageDraw, ImageFilter\n",
    "from PIL import Image, ImageFilter\n",
    "import os\n",
    "\n",
    "# Load YOLOv5 models\n",
    "person_model_path = './1-models/Person_Detector.pt'\n",
    "head_model_path = './1-models/Head_detector_fromPersonBox_yolov5.pt'\n",
    "\n",
    "\n",
    "person_model = torch.hub.load('ultralytics/yolov5', 'custom', path=person_model_path)\n",
    "head_model = torch.hub.load('ultralytics/yolov5', 'custom', path=head_model_path)\n",
    "\n",
    "\n",
    "# Define a function to blur faces\n",
    "def blur_faces(image, head_boxes,blur=False):\n",
    "    blurred_image = image.copy()\n",
    "    for box in head_boxes:\n",
    "        x1, y1, x2, y2 = map(int, box)  # Convert to integer coordinates\n",
    "        face_region = image.crop((x1, y1, x2, y2))\n",
    "        if blur:\n",
    "            face_region = face_region.filter(ImageFilter.BLUR)\n",
    "            face_region = face_region.filter(ImageFilter.BLUR)\n",
    "            blurred_face = face_region.filter(ImageFilter.BLUR)\n",
    "\n",
    "        else:\n",
    "            blurred_face = Image.new('RGB', (x2 - x1, y2 - y1), (0, 0, 0))\n",
    "        blurred_image.paste(blurred_face, (x1, y1, x2, y2))\n",
    "    return blurred_image\n",
    "\n",
    "# to ignore other files in dataset and only care about images\n",
    "def is_image_file(filename):\n",
    "    img_extensions = ['.png', '.jpg', '.jpeg', '.bmp', '.gif', '.tiff', '.webp']\n",
    "    return any(filename.lower().endswith(ext) for ext in img_extensions)\n",
    "\n",
    "# Process the dataset\n",
    "input_folder = input_path\n",
    "output_folder = output_path\n",
    "\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for root, _, files in os.walk(input_folder):\n",
    "    for filename in files:\n",
    "        if is_image_file(filename):\n",
    "            image_path = os.path.join(root, filename)\n",
    "            img = Image.open(image_path)\n",
    "            \n",
    "            # Step 1: Detect persons using the first model\n",
    "            results_person = person_model(img)\n",
    "            persons = results_person.pandas().xyxy[0]\n",
    "            person_boxes = persons[persons['name'] == 'person'][['xmin', 'ymin', 'xmax', 'ymax']].values.tolist()\n",
    "            \n",
    "            # Step 2: Detect heads using the second model\n",
    "            head_boxes = []\n",
    "            for box in person_boxes:\n",
    "                x1, y1, x2, y2 = box\n",
    "                person_region = img.crop((x1, y1, x2, y2))\n",
    "                results_head = head_model(person_region)\n",
    "                heads = results_head.pandas().xyxy[0]\n",
    "                if 'head' in heads['name'].values:\n",
    "                    head = heads[heads['name'] == 'head'][['xmin', 'ymin', 'xmax', 'ymax']].values[0]\n",
    "                    head_boxes.append([x1 + head[0], y1 + head[1], x1 + head[2], y1 + head[3]])\n",
    "            \n",
    "            # Step 3: Save YOLO format .txt file with head bounding boxes\n",
    "            rel_image_path = os.path.relpath(image_path, input_folder)\n",
    "            txt_output_path = os.path.join(output_folder, os.path.splitext(rel_image_path)[0] + '.txt')\n",
    "            os.makedirs(os.path.dirname(txt_output_path), exist_ok=True)\n",
    "            \n",
    "            with open(txt_output_path, 'w') as f:\n",
    "                for box in head_boxes:\n",
    "                    f.write(f\"head {box[0]} {box[1]} {box[2]} {box[3]}\\n\")\n",
    "            \n",
    "            # Step 4: Save the new dataset with blurred faces\n",
    "            rel_output_folder = os.path.relpath(output_folder, input_folder)\n",
    "            output_image_path = os.path.join(output_folder, rel_image_path)\n",
    "            os.makedirs(os.path.dirname(output_image_path), exist_ok=True)\n",
    "            \n",
    "            # If blur = False it will put a black box instead of head.\n",
    "            # set blur = True if you do not like the black box!\n",
    "            blurred_image = blur_faces(img, head_boxes, blur = False)\n",
    "            blurred_image.save(output_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "last_tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
